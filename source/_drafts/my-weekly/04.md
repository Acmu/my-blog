### 为什么 0.1 + 0.2 不等于 0.3 ？

来自：图解系统-小林 coding-v1.0

#### 内容

##### 为什么负数要用补码表示？

整数类型在计算机中的存储：以 int 举例，4 个字节（32 位），最高位（1 位）0 代表正数，1 代表负数

补码：把正数的⼆进制全部取反再加 1，⽐如 -1 的⼆进制是把数字 1 的⼆进制取反后再加 1

为什么要引入补码这么麻烦的东西？

如果不用，只是改变符号位，那么我们计算下 `-2+1` 这个过程

```
-2
10000000000000000000000000000010

1
00000000000000000000000000000001

-2 + 1 （答案变成了-3）
10000000000000000000000000000011
```

直接相加这明显答案是不对的，必须要增加额外操作才能使结果正确，而在计算机中，加减法操作是很常用的，为了性能考虑，所以使用了补码，补码直接相加，结果是正确的

```
-2（补码）
11111111111111111111111111111110

1
00000000000000000000000000000001

-1（补码）
11111111111111111111111111111111
```

并且`-1 + -2`也是成立的

```
-1
11111111111111111111111111111111

-2
11111111111111111111111111111110

-3
11111111111111111111111111111101
```

所以这就是使用补码的原因

##### 十进制小数与二进制的转换

如 `8.625` 怎么转换成二进制？

首先 8 就正常转换 `1000`，接着，小数是这样处理的

```
0.625 x 2 === 1.25  记1
0.25 x 2 === 0.5    记0
0.5 x 2 === 1       记1
0                   循环终止
```

所以结果为`1000.101` 但并不是所有小数都可以表示的，比如`0.1`

```
0.1 x 2 === 0.2  记0
0.2 x 2 === 0.4  记0
0.4 x 2 === 0.8  记0
0.8 x 2 === 1.6  记1
0.6 x 2 === 1.2  记1
0.2 x 2 === 0.4  记0 这里开始无限循环了
0.4 x 2 === 0.8  记0
0.8 x 2 === 1.6  记1
0.6 x 2 === 1.2  记1
0.2 x 2 === 0.4  记0 这里开始无限循环了
...
```

你可以发现 `0.2 x 2 === 0.4` 出现了 3 次，即从这里开始了无限循环，**由于计算机的资源是有限的，所以无法用二进制精确表示 0.1，只能用近似值来表示，就是在有限的精度情况下，最大化接近 0.1 的二进制数，于是便造成了精度缺失的情况**（这种情况其实对于我们并不陌生，二进制无法精确表示`0.1` 就像十进制无法精确表示`1/3`一样）

那二进制如何转十进制小数呢，如图：

![image-20211230174310286](https://gitee.com/wen98y/upic/raw/master/uPic/2021-12/31_10:16_qGoaH1.png)

##### 计算机是怎么存小数的？

我们刚才算的`1000.101`是定点数，代表小数点是死的，不能移动，如果你移动了小数点的位置，那么他的值就变了，然而在计算机中是采用浮点数存储的，代表小数点是可以浮动变化位置的，例如`1000.101`可表示为`1.000101 x 2^3`，因为把小数点向左移了 3 位，而且这是二进制，所以只要乘上 2 的 3 次方即可回到原始值，类似科学计数法

科学计数法：

⽐如有个很⼤的⼗进制数 `1230000`，我们可以也可以表示成 `1.23 x 10^6`，这种⽅式就称为科学记数法。

该⽅法在⼩数点左边只有⼀个数字，⽽且把这种整数部分没有前导 0 的数字称为规格化，⽐如 `1.0 x 10^(-9)` 是规格化的科学记数法，⽽ `0.1 x 10^(-9)` 和 `10.0 x 10^(-9)` 就不是了。

那这里要把二进制都存成规格化的科学计数法，也就是`1.000101 x 2^3` ，这时可以发现`1.000101` 中的第一个 1 总是不变的，因为不可能以 0 开头，以 0 开头就不是规格化的了，`2^3`中的 2 也总是不变的，因为总是二进制，所以这两个值可以不用存储，重要的是如下的数据：

-   **尾数** 也就是 `1.000101 x 2^3` 中的`000101`
-   **指数** 也就是 `1.000101 x 2^3` 中的`3`

现在绝⼤多数计算机使⽤的浮点数，是采用 IEEE 制定的国际标准：

```
符号位 + 指数位 + 尾数
```

指数位的⻓度越⻓，数值就越⼤

尾数位的⻓度越⻓，数值就越精度

```
单精度浮点数 float 32位
符号位（1） + 指数位（8） + 尾数（23）

双精度浮点数 double 64位
符号位（1） + 指数位（11） + 尾数（52）
```

因为指数位没有符合位，那么又需要表示负数，所以引入的偏移量，`float`的偏移量是 127，那么如下即可表示`8.26`

```
1000.101 转为浮点
1.000101 x 2^3
存到 float 中，二进制为：
0（符号位） + 10000010（指数：127+3 也就是130的二进制） + 00010100000000000000000（尾数：直接把尾数写到这里，共23位）
```

可使用[binaryconvert](http://www.binaryconvert.com/index.html)验证一下，是一致的

<img src="https://gitee.com/wen98y/upic/raw/master/uPic/2021-12/31_10:16_xRKsHL.png" alt="image-20211230205548497" style="zoom:50%;" />

max value 的计算是不是和这里有关？最大精度，表示的最大数字等？

```
Number.MAX_VALUE
1.7976931348623157e+308
Number.MIN_VALUE
5e-324
Number.EPSILON
2.220446049250313e-16

这些值是怎么算出来的？
```

float 指数范围是 `-126 ~ +127` 为什么只有 254 个，2^8 不是 256 吗？少的数哪里去了（存了 NaN 和 Infinity？）

#### 思考

如何进制转换？[七进制转换](https://acmu.github.io/my-blog/2021/12/30/online-judge/lt504/)

parseInt 是否会受限于数字溢出？是的，太大就变成 Infinity 了

自己可以写个国内版的[binaryconvert](http://www.binaryconvert.com/index.html)，这是[另一个选择](https://www.h-schmidt.net/FloatConverter/IEEE754.html)

cpu 如何使用二进制进行减法 乘除法？

为什么需要数据类型？因为要在内存中存数据，你是什么样的类型，决定了你要开辟多少内存空间

为什么我吧 a 赋值了 0.3，JS 能正确的存 0.3 呢？

参考：

[每个计算机科学家都应该了解的关于浮点运算的知识](https://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html)

[decimal.js](http://mikemcl.github.io/decimal.js/) js 的任意精度运算

[JavaScript 中精度问题以及解决方案](https://www.runoob.com/w3cnote/js-precision-problem-and-solution.html)
